x0 <- x1
alpha_m <- alpha.update(alpha0,theta0,x,y)
}
return(list(theta1 = x1[1,1], theta2 = x1[2,1]))
}
set_eps = 0.0001
set_nlim = 10000
set_alpha0 = 1
theta = c(195.8027,0.0484)
steep_descent_opt(firder_nls,x,y,theta,set_alpha0,set_eps,set_nlim)
steep_descent_opt<-function(fun,x,y,theta0,alpha0,eps,nlim){
iter <- 0
if(is.na(eps)){
eps = 1.0e-6  # set a default value for convergence
}
if(is.na(nlim)){
nlim = 1.0e8   # set a default value of sanity check for computation
}
alpha<-alpha.update(alpha0,theta0,x,y)
alpha_m<-matrix(c(alpha[1],0,0,alpha[2]),byrow=TRUE,2,2)
repeat{
iter <- iter + 1
if(iter > nlim) {
cat("  Exceeded Iteration Limit: Current = ",iter, fill= T)
x1 <- NA
break
}
theta1 <- theta0 -alpha_m%*%fun(theta0,x,y)
err <- sum(abs((theta1 - theta1)/(abs(theta0)+0.0001)))
cat(" Iteration#: ", iter, " Current Estimate: ", theta1, ' Error: ',err, ' Alpha: ', alpha, fill=T)
if(err < eps){ #converge
break
}
theta0 <- theta1
alpha_m <- alpha.update(alpha0,theta0,x,y)
}
return(list(theta1 = theta1[1,1], theta2 = theta1[2,1]))
}
steep_descent_opt(firder_nls,x,y,theta,set_alpha0,set_eps,set_nlim)
set_eps = 0.00001
set_nlim = 10000
set_alpha0 = 1
theta = c(195.8027,0.0484)
steep_descent_opt(firder_nls,x,y,theta,set_alpha0,set_eps,set_nlim)
set_eps = 0.0000001
set_nlim = 10000
set_alpha0 = 1
theta = c(195.8027,0.0484)
steep_descent_opt(firder_nls,x,y,theta,set_alpha0,set_eps,set_nlim)
theta = c(15.8027,0.0484)
steep_descent_opt(firder_nls,x,y,theta,set_alpha0,set_eps,set_nlim)
theta = c(195.8027,0.0484)
steep_descent_opt(firder_nls,x,y,theta,set_alpha0,set_eps,set_nlim)
gauss_newton_opt(x,y,yhat_fun,yhat_derfun,theta,set_eps,set_nlim)
gauss_newton_opt <- function(x,y,fun,der_fun,x0,eps,nlim){
iter <- 0
if(is.na(eps)){
eps = 1.0e-6  # set a default value for convergence
}
if(is.na(nlim)){
nlim = 1.0e8   # set a default value of sanity check for computation
}
repeat{
iter <- iter + 1
if(iter > nlim) {
cat("  Exceeded Iteration Limit: Current = ",iter, fill= T)
x1 <- NA
break
}
A = der_fun(x,x0) # ultilized the vectorized operation in R, which is faster
Z = as.matrix(y- fun(x,x0))
x1 <- x0 + solve(t(A)%*%A)%*%t(A)%*%Z
err <- sum(abs((x1 - x0)/(abs(x0)+0.0001)))
cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps){ #converge
break
}
x0 <- x1
}
return(list(theta1 = x1[1,1], theta2 = x1[2,1]))
}
yhat_fun <- function(x, theta){
theta1 <- theta[1]
theta2 <- theta[2]
yhat <- theta1*x/(x+theta2)
return(yhat)
}
yhat_derfun <- function(x,theta){
theta1 <- theta[1]
theta2 <- theta[2]
der <- matrix(c(x/(x+theta2),-theta1*x/(x+theta2)^2),ncol=2)
return(der)
}
#test
set_eps = 0.001
set_nlim = 10000
theta <- c(195.8027,0.0484)
gauss_newton_opt(x,y,yhat_fun,yhat_derfun,theta,set_eps,set_nlim)
loglhCauchy <- function(theta,x) {
sum(-log(pi)-log(1+(x-theta)^2))
}
x <- c(-13.87,-2.53, -2.44, -2.40, -1.75, -1.34, -1.05, -0.23, -0.07, 0.27, 1.77, 2.76, 3.29, 3.47, 3.71, 3.80, 4.24, 4.53, 43.21, 56.75)
theta <- seq(-100,100,0.1)
plot(theta,sapply(theta,loglhCauchy,x),type="l",ylab="Log Likelihood of Cauchy")
theta <- seq(-50,50,0.1)
plot(theta,sapply(theta,loglhCauchy,x),type="l",ylab="Log Likelihood of Cauchy")
theta <- seq(-50,50,0.1)
plot(theta,sapply(theta,loglhCauchy,x),type="l",ylab="Log Likelihood of Cauchy")
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.0001))
cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps) #convergence check
break
x0 <- x1
}
return(x1)
}
firder_lcauchy <- function(theta,x){
sum(2*(x-theta)/(1+(x-theta)^2))
}
secder_lcauchy <- function(theta,x){
sum((2*(x-theta)^2-2)/(1+(x-theta)^2)^2)
}
start_points <- c(-11, -1, 0, 1.4, 4.1, 4.8, 7, 8, 38)
set_eps = 1.0e-4
set_nlim = 10^5
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
x <- c(-13.87,-2.53, -2.44, -2.40, -1.75, -1.34, -1.05, -0.23, -0.07, 0.27, 1.77, 2.76, 3.29, 3.47, 3.71, 3.80, 4.24, 4.53, 43.21, 56.75)
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.0001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps) #convergence check
break
x0 <- x1
}
return(x1)
}
firder_lcauchy <- function(theta,x){
sum(2*(x-theta)/(1+(x-theta)^2))
}
secder_lcauchy <- function(theta,x){
sum((2*(x-theta)^2-2)/(1+(x-theta)^2)^2)
}
start_points <- c(-11, -1, 0, 1.4, 4.1, 4.8, 7, 8, 38)
set_eps = 1.0e-4
set_nlim = 10^5
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt2 <- function(fun, fisher.fun, data, x0, eps, nlim) {
iter <- 0
if(is.na(eps)){
eps = 1.0e-6  # set a default value for convergence
}
if(is.na(nlim)){
nlim = 1.0e8   # set a default value of sanity check for computation
}
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit ",nlim, fill= T)
x1 <- NA
break
}
#note that we set the inputs for the general fisher function with theta and data
#because fisher information is a function of theta, although we didn't use theta
#for the fisher information of Cauchy
x1 <- x0 + fun(x0,data)/fisher.fun(x0, data)
err <- abs((x1 - x0)/(abs(x0)+0.0001))
cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps) #convergence check
break
x0 <- x1
}
return(x1)
}
fisher_cauchy <- function(theta, data){
length(data)/2
}
set_eps = 1.0e-4
set_nlim = 10^5
for(x0 in start_points){
theta_mle = newton_raphson_opt2(firder_lcauchy, fisher_cauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method(fisher) with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt2 <- function(fun, fisher.fun, data, x0, eps, nlim) {
iter <- 0
if(is.na(eps)){
eps = 1.0e-6  # set a default value for convergence
}
if(is.na(nlim)){
nlim = 1.0e8   # set a default value of sanity check for computation
}
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit ",nlim, fill= T)
x1 <- NA
break
}
#note that we set the inputs for the general fisher function with theta and data
#because fisher information is a function of theta, although we didn't use theta
#for the fisher information of Cauchy
x1 <- x0 + fun(x0,data)/fisher.fun(x0, data)
err <- abs((x1 - x0)/(abs(x0)+0.0001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps) #convergence check
break
x0 <- x1
}
return(x1)
}
fisher_cauchy <- function(theta, data){
length(data)/2
}
set_eps = 1.0e-4
set_nlim = 10^5
for(x0 in start_points){
theta_mle = newton_raphson_opt2(firder_lcauchy, fisher_cauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method(fisher) with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.0001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps) #convergence check
break
x0 <- x1
}
return(x1)
}
firder_lcauchy <- function(theta,x){
sum(2*(x-theta)/(1+(x-theta)^2))
}
secder_lcauchy <- function(theta,x){
sum((2*(x-theta)^2-2)/(1+(x-theta)^2)^2)
}
start_points <- c(-11, -1, 0, 1.4, 4.1, 4.8, 7, 8, 38)
set_eps = 1.0e-4
set_nlim = 10^5
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps) #convergence check
break
x0 <- x1
}
return(x1)
}
firder_lcauchy <- function(theta,x){
sum(2*(x-theta)/(1+(x-theta)^2))
}
secder_lcauchy <- function(theta,x){
sum((2*(x-theta)^2-2)/(1+(x-theta)^2)^2)
}
start_points <- c(-11, -1, 0, 1.4, 4.1, 4.8, 7, 8, 38)
set_eps = 1.0e-4
set_nlim = 10^5
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, 0, eps=set_eps, nlim=set_nlim)
theta_mle
newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, -11, eps=set_eps, nlim=set_nlim)
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps || abs(fun(x0,data))<1e-10) #convergence check
break
x0 <- x1
}
return(x1)
}
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps || abs(der_fun(x0,data))<1e-8) #convergence check
break
x0 <- x1
}
return(x1)
}
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
if(err < eps || abs(der_fun(x0,data))<1e-10) #convergence check
break
x0 <- x1
}
return(x1)
}
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
newton_raphson_opt <- function(fun, der_fun, data, x0, eps, nlim) {
iter <- 0
repeat {
iter <- iter + 1
if(iter > nlim) {
cat(" Exceeded Iteration Limit : ",nlim, fill= T)
x1 <- NA
break
}
x1 <- x0 - fun(x0,data)/der_fun(x0,data)
err <- abs((x1 - x0)/(abs(x0)+0.001))
#cat(" Iteration#: ", iter, " Current Estimate: ", x1, ' Error: ',err,fill=T)
# make sure the second derivative is not 0
if(err < eps || abs(der_fun(x1,data))<1e-10) #convergence check
break
x0 <- x1
}
return(x1)
}
for(x0 in start_points){
theta_mle = newton_raphson_opt(firder_lcauchy, secder_lcauchy, data=x, x0, eps=set_eps, nlim=set_nlim)
cat("MLE of theta via the Newton-Raphson method with start point ", x0, ' is ', theta_mle,fill=T)
}
p_x =  function(theta, x){
-n*log(2*pi)+sum(log(1-cos(xs-theta)))
}
x =  c(0.52, 1.96, 2.22, 2.28, 2.28, 2.46, 2.50, 2.53, 2.54, 2.99,
3.47, 3.53, 3.7, 3.88, 3.91, 4.04, 4.06,4.82, 4.85,5.46)
length(x)
theta_star = seq(-pi, pi, length = 100)
Y_out = numeric(length(theta_star))
for (i in 1:length(theta_star)){
Y_out[i] = p_x(theta_star[i], x)
}
length(x)
p_x =  function(theta, x){
n = length(x)
-n*log(2*pi)+sum(log(1-cos(xs-theta)))
}
x =  c(0.52, 1.96, 2.22, 2.28, 2.28, 2.46, 2.50, 2.53, 2.54, 2.99,
3.47, 3.53, 3.7, 3.88, 3.91, 4.04, 4.06,4.82, 4.85,5.46)
n = length(x)
theta_star = seq(-pi, pi, length = 100)
Y_out = numeric(length(theta_star))
for (i in 1:length(theta_star)){
Y_out[i] = p_x(theta_star[i], x)
}
p_x =  function(theta, x){
n = length(x)
-n*log(2*pi)+sum(log(1-cos(x-theta)))
}
x =  c(0.52, 1.96, 2.22, 2.28, 2.28, 2.46, 2.50, 2.53, 2.54, 2.99,
3.47, 3.53, 3.7, 3.88, 3.91, 4.04, 4.06,4.82, 4.85,5.46)
n = length(x)
theta_star = seq(-pi, pi, length = 100)
Y_out = numeric(length(theta_star))
for (i in 1:length(theta_star)){
Y_out[i] = p_x(theta_star[i], x)
}
plot(theta_star, Y_out, type ="l", ylab = "log likelihood function",
xlab="theta")
p_x =  function(theta, x){
sum(log((1-cos(x-theta))/(2*pi)))
}
for (i in 1:length(theta_star)){
Y_out[i] = p_x(theta_star[i], x)
}
plot(theta_star, Y_out, type ="l", ylab = "log likelihood function",
xlab="theta")
mean(x)
asin(mean(x) - pi)
y<-function(x){
pi+sin(x)-x.bar
}
install.packages("rootSolve")
setwd("~/Google Drive/Spring 16/ECS 231/ECS231")
flops = read.csv('basic_block_compare.csv')
flobs
flops
flops = read.csv('basic_block_compare.csv',header=F)
flops
flops/10^6
flops = read.csv('basic_block_compare.csv',header=F)/10^6
flops
sizes = seq(100,1500,100)
sizes
library(ggplot2)
perf.dt = data.frame(matrix_size=sizes,basic_mul=flops[,1],block_mul)
perf.dt = data.frame(matrix_size=sizes,basic_mul=flops[,1],block_mul=flops[,2])
perf.dt
library(reshape2)
nperf.dt = melt(perf.dt,id='matrix_size')
nperf.dt
ggplot(data=nperf.dt+aes(x=matrix_size,y=value,colour=variable))
+geom_line()+scale_y_continuous('Performance (Mflops/s)')
library(ggplot2)
ggplot(data=nperf.dt+aes(x=matrix_size,y=value,colour=variable))
+geom_line()+scale_y_continuous('Performance (Mflops/s)')
ggplot(data=nperf.dt+aes(x=matrix_size,y=value,colour=variable))+geom_line()+scale_y_continuous('Performance (Mflops/s)')
nperf.dt
ggplot(data=nperf.dt,aes(x=matrix_size,y=value,colour=variable))+geom_line()+scale_y_continuous('Performance (Mflops/s)')
ggplot(data=nperf.dt,aes(x=matrix_size,y=value,colour=variable))
+geom_line()+scale_y_continuous('Performance (Mflops/s)')
+ggtitle("Basic V.S Block Matrix-Matrix Multiplication")
ggplot(data=nperf.dt,aes(x=matrix_size,y=value,colour=variable))+
geom_line()+scale_y_continuous('Performance (Mflops/s)')+
ggtitle("Basic V.S Block Matrix-Matrix Multiplication")
blocks = read.csv('block_size_compare.csv',header=F)
names(blocks) = c('BlockSize','MatrixSize','Performance(Mflops/s)')
blocks
blocks_dt = melt(blocks, id = 'BlockSize')
head(blocks_dt)
nperf.dt
perf.dt
ggplot(blocks, aes(x = MatrixSize, y = Performance(Mflops/s))) +
geom_point(aes(color = factor(BlockSize)))
names(blocks) = c('BlockSize','MatrixSize','Performance')
ggplot(blocks, aes(x = MatrixSize, y = Performance)) +
geom_point(aes(color = factor(BlockSize)))
ggplot(blocks, aes(x = MatrixSize, y = Performance)) +
geom_line(aes(color = factor(BlockSize)))
blocks[,3] = blocks[,3]/10^6
blocks
ggplot(blocks, aes(x = MatrixSize, y = Performance)) +
geom_line(aes(color = factor(BlockSize)))
blocks = read.csv('block_size_compare.csv',header=F)
blocks[,3] = blocks[,3]/10^6
names(blocks) = c('BlockSize','MatrixSize','Performance')
ggplot(blocks, aes(x = MatrixSize, y = Performance)) +
geom_line(aes(color = factor(BlockSize)))+scale_y_continuous('Performance (Mflops/s)')+
ggtitle("Different Block Matrix-Matrix Multiplications")
blocks = read.csv('block_size_compare.csv',header=F)
blocks[,3] = blocks[,3]/10^6
names(blocks) = c('BlockSize','MatrixSize','Performance')
ggplot(blocks, aes(x = MatrixSize, y = Performance)) +
geom_line(aes(color = factor(BlockSize)))+scale_y_continuous('Performance (Mflops/s)')+
ggtitle("Different Block Matrix-Matrix Multiplications")
